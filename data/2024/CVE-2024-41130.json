{
  "_annotation": {
    "cna": "github_m",
    "cve_id": "CVE-2024-41130",
    "description": "llama.cpp provides LLM inference in C/C++. Prior to b3427, llama.cpp contains a null pointer dereference in gguf_init_from_file. This vulnerability is fixed in b3427.",
    "generated_from": "https://raw.githubusercontent.com/anchore/cve-data-enrichment/main/data/anchore/2024/CVE-2024-41130.json",
    "reason": "Added CPE configurations because not yet analyzed by NVD.",
    "references": [
      "https://github.com/ggerganov/llama.cpp/commit/07283b1a90e1320aae4762c7e03c879043910252",
      "https://github.com/ggerganov/llama.cpp/security/advisories/GHSA-49q7-2jmh-92fp"
    ]
  },
  "cve": {
    "configurations": [
      {
        "nodes": [
          {
            "cpeMatch": [
              {
                "criteria": "cpe:2.3:a:ggerganov:llama.cpp:*:*:*:*:*:*:*:*",
                "matchCriteriaId": "CDEE8AC9-DDC9-5808-9B86-CA186D0285F0",
                "versionEndExcluding": "b3427",
                "vulnerable": true
              }
            ],
            "negate": false,
            "operator": "OR"
          },
          {
            "cpeMatch": [
              {
                "criteria": "cpe:2.3:a:ggml:llama.cpp:*:*:*:*:*:*:*:*",
                "matchCriteriaId": "D60FB0D9-E09B-48B8-9089-1B0C102F337F",
                "versionEndExcluding": "b3427",
                "vulnerable": true
              }
            ],
            "negate": false,
            "operator": "OR"
          }
        ]
      }
    ]
  }
}