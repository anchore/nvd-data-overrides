{
  "_annotation": {
    "cna": "github_m",
    "cve_id": "CVE-2025-48956",
    "description": "vLLM is an inference and serving engine for large language models (LLMs). From 0.1.0 to before 0.10.1.1, a Denial of Service (DoS) vulnerability can be triggered by sending a single HTTP GET request with an extremely large header to an HTTP endpoint. This results in server memory exhaustion, potentially leading to a crash or unresponsiveness. The attack does not require authentication, making it exploitable by any remote user. This vulnerability is fixed in 0.10.1.1.",
    "generated_from": "https://raw.githubusercontent.com/anchore/cve-data-enrichment/main/data/anchore/2025/CVE-2025-48956.json",
    "modified": "2025-08-21T15:02:09.023000+00:00",
    "published": "2025-08-21T14:41:03.889000+00:00",
    "reason": "Added CPE configurations because not yet analyzed by NVD.",
    "references": [
      "https://github.com/vllm-project/vllm/commit/d8b736f913a59117803d6701521d2e4861701944",
      "https://github.com/vllm-project/vllm/pull/23267",
      "https://github.com/vllm-project/vllm/security/advisories/GHSA-rxc4-3w6r-4v47"
    ]
  },
  "cve": {
    "configurations": [
      {
        "nodes": [
          {
            "cpeMatch": [
              {
                "criteria": "cpe:2.3:a:vllm-project:vllm:*:*:*:*:*:python:*:*",
                "matchCriteriaId": "A456E72C-D8F3-5D84-AF49-9219A220D89F",
                "versionEndExcluding": "0.10.1.1",
                "versionStartIncluding": "0.1.0",
                "vulnerable": true
              }
            ],
            "negate": false,
            "operator": "OR"
          }
        ]
      }
    ]
  }
}